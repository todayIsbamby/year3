# -*- coding: utf-8 -*-
"""Lab4.1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IMMorMOx5waABmYPsk24dur2C_WmWOKW
"""

#Array, image processing
import cv2
import numpy as np
import matplotlib.pyplot as plt
#Model Operation
from keras import Model, Input
import keras.utils as image
# from keras.wrappers.scikit_learn import KerasRegressor
from tensorflow import keras
from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, UpSampling2D
from tensorflow.keras.callbacks import EarlyStopping
from tensorflow.keras.preprocessing.image import load_img, img_to_array

from sklearn.model_selection import train_test_split
from sklearn.model_selection import GridSearchCV
from sklearn import metrics
from google.colab import drive
# io
import glob
from tqdm import tqdm
import warnings;
warnings.filterwarnings('ignore')

from matplotlib.cbook import index_of
#อ่านไฟล์ภาพทั้งหมดเก็บในในรูป array (จำนวนภาพไม่น้อยกว่า 100 ภาพ)
fname=glob.glob("/content/drive/MyDrive/datasetimgs/face_mini/*/*.jpg")
imgs = []
for i in range(len(fname)):
    image = load_img(fname[i], target_size=(100, 100), interpolation="nearest")
    image_array = img_to_array(image)
    imgs.append(image_array)
    #imgs.append(np.array(image_array) / 255.0)


#Normalzied ภาพ (เพื่อให้ค่า pixel intensity = [0, 1])
imgs=np.array(imgs) / 255.0
# #Append images to an array
# แบ่งชุดข้อมูลเป็น Training_data, Testing_data (70 : 30)
train_x, test_x = train_test_split(imgs, random_state=25, test_size=0.3)

# แบ่งชุดข้อมูล Training_data เป็น Training_data, Validation_data (80:20)
train_x, val_x = train_test_split(train_x, random_state=25, test_size=0.2)

# กำหนด noise parameters
noise_mean = 0
noise_std = 1
noise_factor = 0.2
train_x_noise = train_x + (noise_factor * np.random.normal(loc=noise_mean, scale=noise_std, size=train_x.shape))
val_x_noise = val_x  + (noise_factor * np.random.normal(loc=noise_mean, scale=noise_std, size=val_x.shape) )
test_x_noise = test_x  + (noise_factor * np.random.normal(loc=noise_mean, scale=noise_std, size=test_x.shape) )

#select img index for display
index_to_visualize=5
index_to_visualize1=6
index_to_visualize2=7

#Display result
fig=plt.figure(figsize=(10,5))

plt.subplot(1, 3, 1)  # Use 'i' to iterate through the indices
plt.title("Original Image")
plt.imshow(train_x[index_to_visualize])
plt.axis('off')

plt.subplot(1, 3, 2)
plt.title("Original Image")
plt.imshow(train_x[index_to_visualize1])
plt.axis('off')

plt.subplot(1, 3, 3)
plt.title("Original Image")
plt.imshow(train_x[index_to_visualize2])
plt.axis('off')
#///////////////////////////////////////////////////////////////////////////////

fig=plt.figure(figsize=(10,10))
plt.subplot(2, 3, 1)
plt.imshow(train_x_noise[index_to_visualize])
plt.title("Noisy Image")
plt.axis('off')

plt.subplot(2, 3, 2)
plt.imshow(train_x_noise[index_to_visualize1])
plt.title("Noisy Image")
plt.axis('off')

plt.subplot(2, 3, 3)
plt.imshow(train_x_noise[index_to_visualize2])
plt.title("Noisy Image")
plt.axis('off')

plt.show()